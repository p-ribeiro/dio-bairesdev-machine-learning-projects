# Análise automática de vulnerabilidades de código a partir de um diagrama arquitetural (STRIDE)
Documento passo-a-passo para implementar uma solução em Python + FastAPI + Azure OpenAI que: recebe uma imagem da arquitetura, extrai componentes, mapeia para código-fonte e gera análise de ameaças STRIDE (com recomendações).

Resumo rápido
- Entrada: imagem do diagrama arquitetural (PNG/JPEG/SVG).
- Saída: relatório JSON com ameaças STRIDE por componente, evidências no código e recomendações acionáveis.
- Componentes principais: pré-processamento de imagem (OCR/detecção), reconstrução de modelo arquitetural, vinculação a arquivos/camadas do código, análise automática (SAST/SCA/linters/AST), enriquecimento com Azure OpenAI via prompt engineering, API FastAPI para orquestração.

1. Premissas e escopo
- Repositório do código está disponível no mesmo workspace ou acessível (clone local).
- Suporta múltiplas linguagens — adaptar ferramentas por linguagem (Python, JS/TS, Java, Go, etc.).
- Não substitui revisão humana; LLMs e scanners trazem hipóteses que precisam validação.

2. Arquitetura de alto nível
- FastAPI endpoint /analyze: recebe imagem (+metadata opcional).
- Pipeline:
  1. Image processor: OCR (Tesseract / Azure CV) + detect shapes/setas.
  2. Graph builder: converte detecção em componentes e conexões.
  3. Code linker: localiza arquivos/serviços correspondentes (heurísticas / import-graph).
  4. Static analysis runner: roda SAST/SCA/linters sobre arquivos vinculados.
  5. Aggregator + prompt builder: agrega sinais e chama Azure OpenAI com template STRIDE.
  6. Resposta: JSON com ameaças + evidências + recomendações.
- Persistência opcional: DB para auditoria, raw_model_response, hashes.

3. Processamento da imagem (passos)
- Recepção e validação do upload (verificar mime-type).
- Pré-processamento:
  - normalizar tamanho/dpi, binarizar, remover ruído.
  - Converter SVG → PNG se necessário.
- OCR para labels:
  - Tesseract (local) ou Azure Computer Vision OCR (recomendado para maior acurácia).
- Detecção de formas e setas:
  - OpenCV para detecção de retângulos/círculos e linhas; heurísticas para inferir relações (seta aponta de X a Y).
  - Alternativa: modelo de detecção (YOLO) se diagramas variados.
- Construir representação estrutural:
  - componentes = [{id, name, type (db, api, web, auth), bounding_box, labels, exposures, notes}]
  - connections = [{from, to, protocol, arrow_type}]

4. Mapear componentes para código (code linking)
- Estratégias:
  - nome/classe/label matching: buscar strings extraídas no repositório (grep / ripgrep).
  - API surface matching: buscar rotas, arquivos Docker, compose, k8s manifests, package.json, requirements.
  - Call-graph / import-graph: gerar grafo (Python: ast + imports, JS: dependency-cruiser), usar networkx para inferir serviço/module ownership.
  - Heurísticas: pasta names (auth, api, core), Docker service names, repository tags.
- Resultado: mapping = [{component_id, file_paths: [...], language, entrypoints}]

5. Análise automática do código (SAST + SCA + linters)
- Ferramentas por exemplo (instalar via pip/npm/apt/choco):
  - Python: bandit, semgrep, mypy, pip-audit, safety
  - Node: eslint, npm audit, snyk (CLI)
  - Java: spotbugs, checkstyle, dependency-check
  - Containers/infra: trivy, terrascan/checkov, tfsec
- Execução:
  - Rodar análises apenas nos file_paths do component para reduzir ruído.
  - Coletar outputs estruturados (JSON quando possível).
- Exemplos de comandos (Windows / PowerShell):
````bash
# instalar exemplos
pip install bandit semgrep pip-audit
npm install -g eslint
# rodar Bandit recursivo e gerar JSON
bandit -r . -f json -o bandit_report.json
# pip-audit
pip-audit -r requirements.txt -f json -o pip_audit.json
# Semgrep (config custom rules)
semgrep --config=auto --json --output=semgrep.json
````
- Extrair evidências: arquivo, linha, snippet, tipo de vulnerabilidade, severidade.

6. Agregação de sinais e prompt engineering
- Construir contexto conciso para o LLM:
  - Sumário arquitetural (component list + exposures).
  - Evidências do código (top N findings por componente).
  - Policies/constraints (ex.: "concentrar em STRIDE, retorno JSON no schema X").
- Fornecer few-shot examples que mapeiam evidência -> ameaça STRIDE.
- Forçar saída JSON com schema estrito e validação posterior.

Exemplo de prompt (resumido):
````text
Você é um especialista em segurança. Dada a arquitetura e as evidências de código abaixo, gere uma análise STRIDE por componente. Retorne somente JSON válido no formato: {components:[{id,name}], threats:[{component_id, stride_type, description, evidence, probability, impact, recommendation}]}.

Arquitetura:
- components: [...]
Evidências (exemplo):
- component_id: auth-service
  findings:
  - bandit: use of eval() in auth/utils.py:45
  - pip-audit: dependency jwtlib vX has vulnerability CVE-XXXX

Produza análise STRIDE agora.
````
7. JSON schema de saída (exemplo)
````json
{
  "components": [{"id":"auth","name":"Auth Service"}],
  "threats": [
    {
      "component_id":"auth",
      "stride_type":"Spoofing",
      "description":"Uso de eval() permite execução ...",
      "evidence":[{"tool":"bandit","file":"auth/utils.py","line":45}],
      "probability":"High",
      "impact":"High",
      "recommendation":"Remover eval; usar parser seguro; adicionar tests"
    }
  ],
  "raw_model_response": {...}
}
````

8. Validação, priorização e enriquecimento
- Validar JSON (pydantic).
- Priorizar por risco (probability x impact). Mapear a severidade para CVSS quando possível.
- Enriquecer com referências (CVE links) usando OSV/Dependabot APIs.

9. Integração CI/CD e automações
- Adicionar job no pipeline (GitHub Actions / Azure Pipelines) que:
  - Roda análise local/limitada em PRs.
  - Emita comentários no PR com resumo STRIDE e evidências.
- Exemplo: fluxo PR → rodar SAST → gerar report → chamar endpoint Azure OpenAI para sumarizar → postar comentário.

10. Métricas e avaliação
- Medir falsos positivos/negativos: coletar revisão humana em amostras.
- Métricas: precision/recall por tipo STRIDE, tempo médio por análise, taxa de aceitação de recomendações.
- Feedback loop: usar casos verificados para ajustar prompts e regras semânticas.

11. Segurança operacional e privacidade
- Nunca enviar segredos/keys/fragments inteiros ao LLM; filtrar tokens/credentials das evidências.
- Armazenar AZURE keys em Key Vault / variáveis de ambiente; não commitar.
- Rate-limit e autenticação do endpoint FastAPI (API key / OAuth).

12. Entregáveis mínimos para POC
- FastAPI endpoint /analyze que:
  - recebe imagem, retorna JSON STRIDE com threats + evidences (mock pode ser aceitável no início).
- Pipeline local para executar Bandit/Semgrep e gerar JSON.
- Prompt templates versionados e exemplos de imagens + respostas.
- Documentação e testes unitários para parser/aggregator.

13. Checklist de implementação
- [ ] Upload & processamento de imagem funcionando
- [ ] OCR + detector de componentes
- [ ] Mapeamento para arquivos do repositório
- [ ] Runner SAST/SCA integrado
- [ ] Prompt template + validação de JSON
- [ ] Endpoint FastAPI e autenticação
- [ ] CI/CD: análise em PRs e feedback
- [ ] Logs, auditoria e armazenamento seguro das respostas

Recursos e ferramentas recomendadas
- OCR: Tesseract, Azure Computer Vision
- Visão: OpenCV, YOLO (opcional)
- SAST: Bandit, Semgrep, SpotBugs, gosec
- SCA: pip-audit, npm audit, Trivy, Snyk
- Graph analysis: ast, javalang, tree-sitter, networkx
- LLM: Azure OpenAI (deployment gpt-4o/gpt-35-turbo) com prompt engineering

